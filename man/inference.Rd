% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/inference.R
\name{inference}
\alias{inference}
\title{Bayesian Inference for a Hierarchical Linear Mixture Model with a Bernoulli Classifier}
\usage{
inference(
  dataMats,
  parameterVals = NULL,
  MCMCout = 1000,
  MCMCburnin = 1000,
  MCMCthin = 1
)
}
\arguments{
\item{dataMats}{A list consisting of four elements.
- ctrl : a matrix of the control subject data.
- pts : a matrix of the patient subject data.
- indexCtrl : a numeric vector indicating which rows of the control subject matrix belong to the same subject.
- indexPat : a numeric vector indicating which rows of the patient subject matrix belong to the same subject.}

\item{parameterVals}{A list or named vector whose names correspond to the parameters of the model and the whose value is the value of the model (hyper-)parameter.}

\item{MCMCout}{The final number of posterior draws (disregarding burn-in and thinning).}

\item{MCMCburnin}{The number of posterior draws discarded for burn-in.}

\item{MCMCthin}{The lag at which to the thin the posterior draws.}
}
\value{
A list of different components of the MCMC output:
\itemize{
\item post : a dataframe of the posterior draws for all variables, where each column is a different variable
\item prior : a data frame of draws from the prior distribution for all variables.
\item postpred : a dataframe of posterior predictions for the patient subject linear model, with a column for x values and columns for 95\% predictive interval and expected values for both the like control and not control models.
\item priorpred : a dataframe of prior predictions for the patient subject model, similar to postpred.
\item classif : a dataframe of whose columns correspond to patient fibres and rows are classifications from individual draws from the posterior distirbution
}
}
\description{
Using \link{rjags} the function fits a hierarchical linear mixture model to a
dataset. The was developed to be able to classify individual fibres within a
2Dmito plot as being a set of data control fibre data points. The model
fundamentally assumes the control data shows strong linearity and anything
diverges from this is not like control.
}
\details{
The inference is implemented using \code{\link[rjags:jags.model]{rjags::jags.model()}}. The model itself
cannot be changed however the parameters and hyper parameters which govern
the model can be updated by using the \code{parameterVals} variable in the
function. This allows for a vast array of different prior beliefs and
information to be imposed upon the model.

The function fits a Bayesian hierarchical linear mixture model, classifying
the patient fibres as like control or not using a Bernoulli classifier.
Let Y be the protein expression level of interest and X be a measure of
mitochondrial mass. Suppose that Y[i,j] is the j-th fibre from sample i. This
notation is purely for convenience here and is not syntax used in the function.
Here normal distributions are described using its mean and precision,
following the convention of \link{rjags}.

The \strong{model}:
Y[i,j] ~ Normal( m[i]*X[i,j]+c[i], tau[i,j] )

Model error: tau[i,j]
\itemize{
\item tau_def if Z[i,j] == 1
\item Gamma( shape_tau, rate_tau ) if Z[i,j] == 0
}

\strong{Classification}: Z[i,j]
\itemize{
\item 0 if i is control
\item Bernoulli( probdef ) if i is patient
}

\strong{Probability of deficiency}: probdef ~ log-Normal(mu_p, tau_p) T(,1)
This is a right-truncated log-normal distribution constraining the parameter
space to be [0,1]. A truncated log-normal was used instead of Beta
distribution (or another density with [0,1] support) as this could more
accurately captured the show shape of the published data ENTER REFERENCE.
The \strong{priors} of the slope and intercept are:
\itemize{
\item m[i]~ Normal( mu_m0, tau_m0 )
\item c[i]~ Normal( mu_c0, tau_c0 )
}

The \strong{hyper-priors} for the slop and intercept are:
. - mu_m0 ~ Normal( mean_mu_m0, prec_mu_m0 )
\itemize{
\item mu_c0 ~ Normal( mean_mu_c0, prec_mu_c0 )
\item tau_m0 ~ Gamma( shape_tau_m0, rate_tau_m0 )
\item tau_c0 ~ Gamma( shape_tau_c0, rate_tau_c0 )
}

The parameters and hyper-parameters which control the model and can be changed using the \code{parameterValue} argument of the function are:
\itemize{
\item mean_mu_m0 : the expected value of a slope. Default: 1.0.
\item prec_mu_m0 : the precision of the expected value of a slope. Default: 16.
\item mean_mu_c0 : the expected value of an intercept. Default: 0.0.
\item prec_mu_c0 : the precision of the expected value of an intercept. Default: 4/9
\item shape_tau_m0 : the shape parameter of a Gamma distribution of the precision of a slope. Default: 1.1956.
\item rate_tau_m0 : the rate parameter of a Gamma distribution of the precision of a slope. Default: 0.04889989.
\item shape_tau_c0 : the shape parameter of a Gamma distribution of the precision of an intercept. Default: 1.1956.
\item rate_tau_c0 : the rate parameter of a Gamma distribution of the precision of an intercept. Default: 0.04889989.
\item shape_tau : shape parameter of a Gamma distribution of the precision in the model for healthy, like-control, fibres. Defualt: 41.048809.
\item rate_tau : the rate parameter of a Gamma distribution of the precision in the model for healthy, like-control, fibres. Default: 2.048809.
\item mu_p : the expected value for the proportion of deficiency in the dataset. Default: -2.549677.
\item tau_p : the precision for the proportion of deficiency in the dataset. Default: 0.9549515.
\item tau_def : the precision used to classif fibres which are not like control. Default: 0.0001.
}

The model is implemented in JAGS using the following model string:

\if{html}{\out{<div class="sourceCode r">}}\preformatted{"
model \{
 for(i in 1:nCtrl)\{
    Yctrl[i] ~ dnorm(m[index[i]]*Xctrl[i]+c[index[i]], tau_norm)
 \}
 for(j in 1:nPat)\{
   Ypat[j] ~ dnorm(m[nCrl+1]*Xpat[j]+c[nCrl+1], tau_hat[j])
   tau_hat[j] = ifelse(class[j]==1, tau_def, tau_norm)
   class[j] ~ dbern(probdef)
 \}
 for(k in 1:Nsyn)\{
   Ysyn_norm[k] ~ dnorm(m[nCrl+1]*Xsyn[k]+c[nCrl+1], tau_norm)
   Ysyn_def[k] ~ dnorm(m[nCrl+1]*Xsyn[k]+c[nCrl+1], tau_def)
 \}
 tau_norm ~ dgamma(shape_tau, rate_tau)
 probdef ~ dlnorm(mu_p, tau_p) T(,1)
 for(i in 1:(nCrl+1))\{
   m[i] ~ dnorm(mu_m0, tau_m0)
   c[i] ~ dnorm(mu_c0, tau_c0)
 \}

 # Parent distribution for the slope and intercept
 m_pred ~ dnorm(mu_m0, tau_m0)
 c_pred ~ dnorm(mu_c0, tau_m0)

 # Hyper-priors
 mu_m0 ~ dnorm( mean_mu_m0, prec_mu_m0 )
 mu_c0 ~ dnorm( mean_mu_c0, prec_mu_c0 )
 tau_m0 ~ dgamma( shape_tau_m0, rate_tau_m0 )
 tau_c0 ~ dgamma( shape_tau_c0, rate_tau_c0 )
\}
"
#> [1] "\\nmodel \{\\n for(i in 1:nCtrl)\{\\n    Yctrl[i] ~ dnorm(m[index[i]]*Xctrl[i]+c[index[i]], tau_norm)\\n \}\\n for(j in 1:nPat)\{\\n   Ypat[j] ~ dnorm(m[nCrl+1]*Xpat[j]+c[nCrl+1], tau_hat[j])\\n   tau_hat[j] = ifelse(class[j]==1, tau_def, tau_norm)\\n   class[j] ~ dbern(probdef)\\n \}\\n for(k in 1:Nsyn)\{\\n   Ysyn_norm[k] ~ dnorm(m[nCrl+1]*Xsyn[k]+c[nCrl+1], tau_norm)\\n   Ysyn_def[k] ~ dnorm(m[nCrl+1]*Xsyn[k]+c[nCrl+1], tau_def)\\n \}\\n tau_norm ~ dgamma(shape_tau, rate_tau)\\n probdef ~ dlnorm(mu_p, tau_p) T(,1)\\n for(i in 1:(nCrl+1))\{\\n   m[i] ~ dnorm(mu_m0, tau_m0)\\n   c[i] ~ dnorm(mu_c0, tau_c0)\\n \}\\n\\n # Parent distribution for the slope and intercept\\n m_pred ~ dnorm(mu_m0, tau_m0)\\n c_pred ~ dnorm(mu_c0, tau_m0)\\n\\n # Hyper-priors\\n mu_m0 ~ dnorm( mean_mu_m0, prec_mu_m0 )\\n mu_c0 ~ dnorm( mean_mu_c0, prec_mu_c0 )\\n tau_m0 ~ dgamma( shape_tau_m0, rate_tau_m0 )\\n tau_c0 ~ dgamma( shape_tau_c0, rate_tau_c0 )\\n\}\\n"
}\if{html}{\out{</div>}}
}
